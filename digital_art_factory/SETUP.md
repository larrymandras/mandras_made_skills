# Digital Art Factory — Setup Guide

Complete setup for the `/digital-art-factory` Claude Code skill.

---

## Prerequisites

- Claude Code CLI installed and authenticated
- Google account with Google Drive
- OpenAI API key with access to `gpt-image-1`
- `jq` installed (for JSON parsing and base64 decoding in the pipeline)

---

## Step 1: Install rclone

rclone is the CLI tool used to read from and write to Google Drive.

### Windows
```powershell
winget install Rclone.Rclone
```
Or download from https://rclone.org/downloads/ and add to PATH.

### macOS
```bash
brew install rclone
```

### Linux (Debian/Ubuntu)
```bash
sudo apt install rclone
```

### Linux (generic)
```bash
curl https://rclone.org/install.sh | sudo bash
```

Verify:
```bash
rclone --version
```

---

## Step 2: Install jq

Used to parse OpenAI API JSON responses and extract base64 image data.

### Windows
```powershell
winget install jqlang.jq
```

### macOS
```bash
brew install jq
```

### Linux
```bash
sudo apt install jq
```

Verify:
```bash
jq --version
```

---

## Step 3: Configure rclone for Google Drive

Run the interactive config wizard:

```bash
rclone config
```

Follow these steps in the wizard:
1. Press `n` → New remote
2. Name: **`gdrive`** (must be exactly this — the skill uses `gdrive:` prefix)
3. Storage type: Select **Google Drive** (type the number shown)
4. Client ID: Leave blank (press Enter)
5. Client Secret: Leave blank (press Enter)
6. Scope: Choose `1` (Full access to all files)
7. Root folder ID: Leave blank
8. Service account file: Leave blank
9. Advanced config: `n`
10. Auto config: `y` — browser will open for OAuth
11. Sign in with your Google account and grant access
12. Team Drive: `n`
13. Confirm and quit config

Test the connection:
```bash
rclone ls gdrive:
```
You should see your Google Drive root files listed.

---

## Step 4: Create the Three Google Drive Folders

```bash
rclone mkdir "gdrive:daf-daily-references"
rclone mkdir "gdrive:daf-archive"
rclone mkdir "gdrive:daf-new-images"
```

Verify they exist:
```bash
rclone lsd gdrive:
```

You should see all three `daf-*` folders listed.

---

## Step 5: Set Your OpenAI API Key

### Option A: Shell profile (persistent, recommended)

Add to `~/.bashrc`, `~/.zshrc`, or `~/.bash_profile`:
```bash
export OPENAI_API_KEY="sk-..."
```

Reload:
```bash
source ~/.bashrc   # or ~/.zshrc
```

### Option B: Set for current session only
```bash
export OPENAI_API_KEY="sk-..."
```

### Option C: For cron jobs

When using cron, the shell profile is not loaded. Set the key directly in
`~/daf-cron.sh` (generated by `/digital-art-factory cron-setup`):
```bash
export OPENAI_API_KEY="sk-..."
```

Verify the key is accessible:
```bash
echo $OPENAI_API_KEY
```

---

## Step 6: Upload Reference Images

Place your reference images in the queue folder. The pipeline processes the
**oldest uploaded file** each run.

```bash
# Upload a single image
rclone copy /path/to/reference.jpg "gdrive:daf-daily-references/"

# Upload multiple images
rclone copy /path/to/references/ "gdrive:daf-daily-references/"
```

Or upload directly via the Google Drive web UI — rclone will see them.

**Supported formats:** JPEG, PNG, WebP (any format Claude vision can read)

**Tips:**
- Name files descriptively — the filename appears in logs and reports
- Upload multiple images to build a queue — the skill will process one per run
- Images are moved to `daf-archive` after successful processing

---

## Step 7: Full Verification Checklist

Run through these checks before the first live run:

```bash
# 1. rclone can reach Google Drive
rclone ls "gdrive:daf-daily-references"

# 2. OpenAI key is set
echo $OPENAI_API_KEY | head -c 10   # Should show: sk-...

# 3. jq is installed
jq --version

# 4. Reference image is in queue
rclone lsjson "gdrive:daf-daily-references" --order-by "modtime,ascending"
# → Should show at least one file

# 5. Temp directories are writable
mkdir -p /tmp/daf-ref /tmp/daf-output && echo "OK"
```

---

## Step 8: First Run

```
/digital-art-factory run
```

Monitor what Claude does:
1. Lists the queue → picks oldest file
2. Downloads it to `/tmp/daf-ref/`
3. Reads and analyzes the image (you'll see the visual DNA JSON)
4. Generates 10 prompts
5. Calls OpenAI 10 times (watch for any API errors)
6. Uploads to `gdrive:daf-new-images/`
7. Archives the reference to `gdrive:daf-archive/`
8. Cleans up `/tmp/daf-*`
9. Prints the summary report

---

## Step 9: Set Up Cron (Optional)

For fully automated daily runs:

```
/digital-art-factory cron-setup
```

This creates `~/daf-cron.sh`. Edit it to insert your API key:
```bash
nano ~/daf-cron.sh
```

Make executable and schedule:
```bash
chmod +x ~/daf-cron.sh
crontab -e
```

Add the line (runs daily at 8am):
```
0 8 * * * /bin/bash ~/daf-cron.sh
```

View logs:
```bash
tail -f ~/digital-art-factory.log
```

---

## Troubleshooting

### `rclone: command not found`
rclone is not in PATH. Reinstall or add its location to PATH.

### `Error: directory not found: gdrive:daf-daily-references`
Run `rclone mkdir "gdrive:daf-daily-references"` to create the folder.

### `Error: OPENAI_API_KEY not set`
Set the environment variable — see Step 5 above.

### `jq: command not found`
Install jq — see Step 2 above.

### `jq` returns `null` for image data
The OpenAI API returned an error. Check:
- API key is valid and has gpt-image-1 access
- You have sufficient credits/quota
- The prompt didn't violate content policy

### OAuth token expired
Re-run `rclone config` → select `gdrive` → choose to re-authenticate.

### Images not appearing in Drive after run
Check upload step output — rclone logs show transfer details. Verify
`gdrive:daf-new-images` folder exists.

---

## Cost Estimates (approximate)

| Resource | Cost |
|----------|------|
| gpt-image-1 high quality (1024×1536) | ~$0.19/image |
| 10 images per run | ~$1.90/run |
| Daily runs (30 days) | ~$57/month |
| Claude vision analysis | Included in Claude Code subscription |

Check current OpenAI pricing at platform.openai.com/pricing.

---

## File Locations Summary

| File | Purpose |
|------|---------|
| `~/.config/rclone/rclone.conf` | rclone Google Drive credentials (auto-created) |
| `~/daf-cron.sh` | Cron runner script (created by cron-setup command) |
| `~/digital-art-factory.log` | Cron run log |
| `/tmp/daf-ref/` | Temporary reference image download (auto-cleaned) |
| `/tmp/daf-output/` | Temporary generated images (auto-cleaned) |
